{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP CW 2 - PART B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T20:42:11.202561Z",
     "start_time": "2017-11-27T20:42:10.571056Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "\n",
    "# Seed a random number generator\n",
    "seed = 10102016\n",
    "rng = np.random.RandomState(seed)\n",
    "batch_size = 100\n",
    "# Set up a logger object to print info about the training run to stdout\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.handlers = [logging.StreamHandler()]\n",
    "\n",
    "# The model set up code below is provided as a starting point.\n",
    "# You will probably want to add further code cells for the\n",
    "# different experiments you run.\n",
    "from mlp.helper import train_model_and_plot_stats\n",
    "from mlp.data_providers import EMNISTDataProvider\n",
    "from mlp.layers import *\n",
    "from mlp.errors import CrossEntropyLogSoftmaxError\n",
    "from mlp.models import MultipleLayerModel\n",
    "from mlp.initialisers import ConstantInit, GlorotUniformInit\n",
    "from mlp.learning_rules import GradientDescentLearningRule, AdamLearningRule, RMSPropLearningRule\n",
    "from mlp.penalty import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T20:42:11.779303Z",
     "start_time": "2017-11-27T20:42:11.204367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['inputs', 'targets']\n",
      "['inputs', 'targets']\n",
      "['inputs', 'targets']\n"
     ]
    }
   ],
   "source": [
    "# Create data provider objects for the MNIST data set\n",
    "train_data = EMNISTDataProvider('train', batch_size=batch_size, rng=rng)\n",
    "valid_data = EMNISTDataProvider('valid', batch_size=batch_size, rng=rng)\n",
    "test_data = EMNISTDataProvider('test', batch_size=batch_size, rng=rng)\n",
    "\n",
    "# setup hyperparameters\n",
    "learning_rate = 0.1\n",
    "num_epochs = 1\n",
    "stats_interval = 1\n",
    "input_dim, output_dim, hidden_dim = 784, 47, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T20:55:48.732868Z",
     "start_time": "2017-11-27T20:42:11.781174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerModel(\n",
      "    DropoutLayer(incl_prob=0.8)\n",
      "    ReshapeLayer(output_shape=(1, 28, 28))\n",
      "    ConvolutionalLayer(\n",
      "    num_input_channels=1, num_output_channels=5,\n",
      "    input_dim_1=28, input_dim_2=28,\n",
      "    kernel_dim_1=5, kernel_dim_2=5\n",
      ")\n",
      "    MaxPoolLayer(\n",
      "    num_input_channels=5,\n",
      "    input_dim_1=24, input_dim_2=24,\n",
      "    extent=2, stride=2\n",
      ")\n",
      "    ReluLayer\n",
      "    ConvolutionalLayer(\n",
      "    num_input_channels=5, num_output_channels=10,\n",
      "    input_dim_1=12, input_dim_2=12,\n",
      "    kernel_dim_1=5, kernel_dim_2=5\n",
      ")\n",
      "    MaxPoolLayer(\n",
      "    num_input_channels=10,\n",
      "    input_dim_1=8, input_dim_2=8,\n",
      "    extent=2, stride=2\n",
      ")\n",
      "    ReluLayer\n",
      "    ReshapeLayer(output_shape=(160,))\n",
      "    DropoutLayer(incl_prob=0.8)\n",
      "    AffineLayerWithoutBias(input_dim=160, output_dim=400)\n",
      "    BatchNormalizationLayer(input_dim=400)\n",
      "    ReluLayer\n",
      "    DropoutLayer(incl_prob=0.8)\n",
      "    AffineLayerWithoutBias(input_dim=400, output_dim=400)\n",
      "    BatchNormalizationLayer(input_dim=400)\n",
      "    ReluLayer\n",
      "    AffineLayer(input_dim=400, output_dim=47)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 523.4s to complete\n",
      "    error(train)=7.70e-01, acc(train)=7.43e-01, error(valid)=7.68e-01, acc(valid)=7.43e-01, error(test)=8.03e-01, acc(test)=7.36e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5de2187e817e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m                                     \u001b[0mearlyStop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                     patience=5)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# pkl.dump(output, open('2conv_2DNN_BN_DROPOUT_REG.pkl', 'wb'), protocol=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLP2k1718/mlp/helper.py\u001b[0m in \u001b[0;36mtrain_model_and_plot_stats\u001b[0;34m(model, error, learning_rule, train_data, valid_data, test_data, num_epochs, stats_interval, notebook, displayGraphs, earlyStop, steps, patience)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdisplayGraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLP2k1718/mlp/optimisers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, max_num_epochs, stats_interval)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLP2k1718/mlp/optimisers.py\u001b[0m in \u001b[0;36mdo_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             grads_wrt_params = self.model.grads_wrt_params(\n\u001b[0;32m--> 223\u001b[0;31m                 activations, grads_wrt_outputs)\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_wrt_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLP2k1718/mlp/models.py\u001b[0m in \u001b[0;36mgrads_wrt_params\u001b[0;34m(self, activations, grads_wrt_outputs)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mgrads_wrt_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_wrt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayerWithParameters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStochasticLayerWithParameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 grads_wrt_params += layer.grads_wrt_params(\n",
      "\u001b[0;32m~/MLP2k1718/mlp/layers.py\u001b[0m in \u001b[0;36mbprop\u001b[0;34m(self, inputs, outputs, grads_wrt_outputs)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0m_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0m_grads_wrt_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1599\u001b[0m         output = col2im_indices(_output, inputs.shape, field_height=self.f1, field_width=self.f2, padding=self.padding,\n\u001b[0;32m-> 1600\u001b[0;31m                                 stride=self.stride)\n\u001b[0m\u001b[1;32m   1601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"error transforming from column to matrices!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLP2k1718/mlp/layers.py\u001b[0m in \u001b[0;36mcol2im_indices\u001b[0;34m(cols, x_shape, field_height, field_width, padding, stride)\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0mcols_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfield_height\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfield_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0mcols_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols_reshaped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_padded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trial=1\n",
    "train_data.reset()\n",
    "valid_data.reset()\n",
    "test_data.reset()\n",
    "\n",
    "weights_init = GlorotUniformInit(rng=rng)\n",
    "biases_init = ConstantInit(0.)\n",
    "\n",
    "model = MultipleLayerModel([\n",
    "    DropoutLayer(rng=rng, incl_prob=.8, share_across_batch=True),\n",
    "    ReshapeLayer(output_shape=(1, 28, 28)),\n",
    "    ConvolutionalLayer(\n",
    "        num_input_channels=1,\n",
    "        num_output_channels=5,\n",
    "        input_dim_1=28,\n",
    "        input_dim_2=28,\n",
    "        kernel_dim_1=5,\n",
    "        kernel_dim_2=5,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        kernels_penalty=L2Penalty(1e-6)),\n",
    "    MaxPoolingLayer(\n",
    "        num_input_channels=5, input_dim_1=24, input_dim_2=24, extent=2),\n",
    "    ReluLayer(),\n",
    "    ConvolutionalLayer(\n",
    "        num_input_channels=5,\n",
    "        num_output_channels=10,\n",
    "        input_dim_1=12,\n",
    "        input_dim_2=12,\n",
    "        kernel_dim_1=5,\n",
    "        kernel_dim_2=5,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        kernels_penalty=L2Penalty(1e-6)),\n",
    "    MaxPoolingLayer(\n",
    "        num_input_channels=10, input_dim_1=8, input_dim_2=8, extent=2),\n",
    "    ReluLayer(),\n",
    "    ReshapeLayer(output_shape=(4 * 4 * 10,)), # TWO HIDDEN LAYER\n",
    "    DropoutLayer(rng=rng, incl_prob=.8, share_across_batch=True),\n",
    "    AffineLayerWithoutBias(4*4*10, 400, weights_init, weights_penalty=L2Penalty(1e-6)),\n",
    "    BatchNormalizationLayer(input_dim=(400), rng=rng),\n",
    "    ReluLayer(),\n",
    "    DropoutLayer(rng=rng, incl_prob=.8, share_across_batch=True),\n",
    "    AffineLayerWithoutBias(400, 400, weights_init, weights_penalty=L2Penalty(1e-6)),\n",
    "    BatchNormalizationLayer(input_dim=(400), rng=rng),\n",
    "    ReluLayer(),\n",
    "    AffineLayer(400, output_dim, weights_init, biases_init,weights_penalty=L2Penalty(1e-6))\n",
    "])\n",
    "\n",
    "print(model)\n",
    "error = CrossEntropyLogSoftmaxError()\n",
    "learning_rule = AdamLearningRule(learning_rate=1e-1) # Increase because of BN\n",
    "\n",
    "# Remember to use notebook=False when you write a script to be run in a terminal\n",
    "output = train_model_and_plot_stats(model,\n",
    "                                    error,\n",
    "                                    learning_rule,\n",
    "                                    train_data,\n",
    "                                    valid_data,\n",
    "                                    test_data,\n",
    "                                    num_epochs,\n",
    "                                    stats_interval,\n",
    "                                    notebook=False,\n",
    "                                    displayGraphs=False,\n",
    "                                    earlyStop=True,\n",
    "                                    steps=3,\n",
    "                                    patience=5)\n",
    "\n",
    "# pkl.dump(output, open('2conv_2DNN_BN_DROPOUT_REG.pkl', 'wb'), protocol=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial=1\n",
    "train_data.reset()\n",
    "valid_data.reset()\n",
    "test_data.reset()\n",
    "\n",
    "weights_init = GlorotUniformInit(rng=rng)\n",
    "biases_init = ConstantInit(0.)\n",
    "\n",
    "model = MultipleLayerModel([\n",
    "    DropoutLayer(rng=rng, incl_prob=.8, share_across_batch=True),\n",
    "    ReshapeLayer(output_shape=(1, 28, 28)),\n",
    "    ConvolutionalLayer(\n",
    "        num_input_channels=1,\n",
    "        num_output_channels=5,\n",
    "        input_dim_1=28,\n",
    "        input_dim_2=28,\n",
    "        kernel_dim_1=5,\n",
    "        kernel_dim_2=5,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        kernels_penalty=L2Penalty(1e-6)),\n",
    "    MaxPoolingLayer(\n",
    "        num_input_channels=5, input_dim_1=24, input_dim_2=24, extent=2),\n",
    "    ReluLayer(),\n",
    "    ConvolutionalLayer(\n",
    "        num_input_channels=5,\n",
    "        num_output_channels=10,\n",
    "        input_dim_1=12,\n",
    "        input_dim_2=12,\n",
    "        kernel_dim_1=5,\n",
    "        kernel_dim_2=5,\n",
    "        padding=0,\n",
    "        stride=1,\n",
    "        kernels_penalty=L2Penalty(1e-6)),\n",
    "    MaxPoolingLayer(\n",
    "        num_input_channels=10, input_dim_1=8, input_dim_2=8, extent=2),\n",
    "    ReluLayer(),\n",
    "    ReshapeLayer(output_shape=(4 * 4 * 10,)), # TWO HIDDEN LAYER\n",
    "    DropoutLayer(rng=rng, incl_prob=.8, share_across_batch=True),\n",
    "    AffineLayerWithoutBias(4*4*10, 400, weights_init, weights_penalty=L2Penalty(1e-6)),\n",
    "    BatchNormalizationLayer(input_dim=(400), rng=rng),\n",
    "    ReluLayer(),\n",
    "    DropoutLayer(rng=rng, incl_prob=.8, share_across_batch=True),\n",
    "    AffineLayerWithoutBias(400, 400, weights_init, weights_penalty=L2Penalty(1e-6)),\n",
    "    BatchNormalizationLayer(input_dim=(400), rng=rng),\n",
    "    ReluLayer(),\n",
    "    AffineLayer(400, output_dim, weights_init, biases_init,weights_penalty=L2Penalty(1e-6))\n",
    "])\n",
    "\n",
    "print(model)\n",
    "error = CrossEntropyLogSoftmaxError()\n",
    "learning_rule = AdamLearningRule(learning_rate=1e-1) # Increase because of BN\n",
    "\n",
    "# Remember to use notebook=False when you write a script to be run in a terminal\n",
    "output = train_model_and_plot_stats(model,\n",
    "                                    error,\n",
    "                                    learning_rule,\n",
    "                                    train_data,\n",
    "                                    valid_data,\n",
    "                                    test_data,\n",
    "                                    num_epochs,\n",
    "                                    stats_interval,\n",
    "                                    notebook=False,\n",
    "                                    displayGraphs=False,\n",
    "                                    earlyStop=True,\n",
    "                                    steps=3,\n",
    "                                    patience=5)\n",
    "\n",
    "# pkl.dump(output, open('2conv_2DNN_BN_DROPOUT_REG.pkl', 'wb'), protocol=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 160,
   "position": {
    "height": "40px",
    "left": "845px",
    "right": "-11px",
    "top": "223px",
    "width": "529px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
