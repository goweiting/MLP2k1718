
%load_ext autoreload
%autoreload 2
from __future__ import print_function

import matplotlib.pyplot as plt
%matplotlib inline
plt.style.use('ggplot')


def train_model_and_plot_stats(model,
                               error,
                               learning_rule,
                               train_data,
                               valid_data,
                               test_data,
                               num_epochs,
                               stats_interval,
                               notebook=True):

    # As well as monitoring the error over training also monitor classification
    # accuracy i.e. proportion of most-probable predicted classes being equal to targets
    data_monitors = {'acc': lambda y, t: (y.argmax(-1) == t.argmax(-1)).mean()}

    # Use the created objects to initialise a new Optimiser instance.
    optimiser = Optimiser(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        data_monitors,
        notebook=notebook)

    # Run the optimiser for 5 epochs (full passes through the training set)
    # printing statistics every epoch.
    stats, keys, run_time = optimiser.train(
        num_epochs=num_epochs, stats_interval=stats_interval)

    # Plot the change in the validation and training set error over training.
    fig_1 = plt.figure(figsize=(8, 4))
    ax_1 = fig_1.add_subplot(111)
    for k in ['error(train)', 'error(valid)']:
        ax_1.plot(
            np.arange(1, stats.shape[0]) * stats_interval,
            stats[1:, keys[k]],
            label=k)
    ax_1.legend(loc=0)
    ax_1.set_xlabel('Epoch number')

    # Plot the change in the validation and training set accuracy over training.
    fig_2 = plt.figure(figsize=(8, 4))
    ax_2 = fig_2.add_subplot(111)
    for k in ['acc(train)', 'acc(valid)']:
        ax_2.plot(
            np.arange(1, stats.shape[0]) * stats_interval,
            stats[1:, keys[k]],
            label=k)
    ax_2.legend(loc=0)
    ax_2.set_xlabel('Epoch number')

    return stats, keys, run_time, fig_1, ax_1, fig_2, ax_2

# The below code will set up the data providers, random number
# generator and logger objects needed for training runs. As
# loading the data from file take a little while you generally
# will probably not want to reload the data providers on
# every training run. If you wish to reset their state you
# should instead use the .reset() method of the data providers.
import numpy as np
import logging
from mlp.data_providers import MNISTDataProvider, EMNISTDataProvider

# Seed a random number generator
seed = 10102016
rng = np.random.RandomState(seed)
batch_size = 100
# Set up a logger object to print info about the training run to stdout
logger = logging.getLogger()
logger.setLevel(logging.INFO)
logger.handlers = [logging.StreamHandler()]

# Create data provider objects for the MNIST data set
train_data = EMNISTDataProvider('train', batch_size=batch_size, rng=rng)
valid_data = EMNISTDataProvider('valid', batch_size=batch_size, rng=rng)
test_data = EMNISTDataProvider('test', batch_size=batch_size, rng=rng)

print("\t\t\tnum_batches * batch_size = size of inputs")
print("train_data\t\t", train_data.num_batches, " * ", train_data.batch_size, " = ", len(train_data.inputs))
print("valid_data\t\t", valid_data.num_batches, " * ", valid_data.batch_size, " = ", len(valid_data.inputs))
print("test_data\t\t", test_data.num_batches, " * ", test_data.batch_size, " = ", len(test_data.inputs))

###### The model set up code below is provided as a starting point.
# You will probably want to add further code cells for the
# different experiments you run.

from mlp.layers import AffineLayer, SoftmaxLayer, SigmoidLayer, ReluLayer, LeakyReluLayer, ELULayer, SELULayer
from mlp.errors import CrossEntropyLogSoftmaxError
from mlp.models import MultipleLayerModel
from mlp.initialisers import ConstantInit, GlorotUniformInit
from mlp.learning_rules import GradientDescentLearningRule
from mlp.optimisers import Optimiser

#setup hyperparameters
learning_rate = 0.01
num_epochs = 60 # TODO: CHANGED HERE FOR TESTING ONLY!
stats_interval = 1
input_dim, output_dim, hidden_dim = 784, 47, 100

func = SigmoidLayer()
experiment_layers_sigmoid = {}

for i in range(1, 10):
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        func,
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        func,
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_layers_sigmoid[i + 1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

# Generate some statistics for SIGMOID layer:
final_valid_err_sigmoid = []
final_valid_acc_sigmoid = []

fig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in experiment_layers_sigmoid.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    final_valid_err_sigmoid.append(stats[-1, keys['error(valid)']])
    final_valid_acc_sigmoid.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

func = ReluLayer()
experiment_layers_relu = {}

for i in range(1, 10):
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        func,
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        func,
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_layers_relu[i + 1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

# Generate some statistics for RELU layer:
final_valid_err_relu = []
final_valid_acc_relu = []

fig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in experiment_layers_relu.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    final_valid_err_relu.append(stats[-1, keys['error(valid)']])
    final_valid_acc_relu.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

func = ELULayer()
experiment_layers_elu = {}

for i in range(1, 10):
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        func,
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        func,
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_layers_elu[i + 1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

# Generate some statistics for SIGMOID layer:
final_valid_err_elu = []
final_valid_acc_elu = []

fig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in experiment_layers_elu.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    final_valid_err_sigmoid.append(stats[-1, keys['error(valid)']])
    final_valid_acc_sigmoid.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

func = SELULayer()
experiment_layers_selu = {}

for i in range(1, 10):
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        func,
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        func,
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_layers_selu[i + 1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

# Generate some statistics for SIGMOID layer:
final_valid_err_selu = []
final_valid_acc_selu = []

fig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in experiment_layers_selu.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    final_valid_err_sigmoid.append(stats[-1, keys['error(valid)']])
    final_valid_acc_sigmoid.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

func = ELULayer()
experiment_units_elu = {}
hidden_layers = 9  # + 1 = 10 layers

hidden_units = [100, 200, 300, 400]
for hidden_dim in hidden_units:
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        func,
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        func,
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * hidden_layers
                               + output_layer)
    print(model, '{} layers'.format(hidden_layers + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_units_elu[hidden_dim] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

hidden_units =[500, 600, 700]
for hidden_dim in hidden_units:
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        func,
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        func,
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * hidden_layers
                               + output_layer)
    print(model, '{} layers'.format(hidden_layers + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_units_elu[hidden_dim] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

exfig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in experiment_units_elu.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    final_valid_err_sigmoid.append(stats[-1, keys['error(valid)']])
    final_valid_acc_sigmoid.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

from mlp.learning_rules import RMSPropLearningRule

expt_LR_RMS = {}
hidden_dim = 500

for i in range(1,10):
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        ReluLayer(),
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        ReluLayer(),
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = RMSPropLearningRule() # Use default parameters here

    expt_LR_RMS[i+1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

fig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in expt_LR_RMS.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    #     final_valid_err_sigmoid.append(stats[-1, keys['error(valid)']])
    #     final_valid_acc_sigmoid.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

from mlp.learning_rules import AdamLearningRule

expt_LR_ADAM = {}
hidden_dim = 500

for i in range(1,10):
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init)
    ]
    output_layer = [
        ReluLayer(),
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        ReluLayer(),
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init)
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = AdamLearningRule() # Use default parameters here

    expt_LR_ADAM[i+1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

len(expt_LR_ADAM)

fig = plt.figure(figsize=(10, 10))
ax1 = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

for (layer, output) in expt_LR_ADAM.items():
    keys = output[1]
    stats = output[0]
    # Store the statistics for this model
    #     final_valid_err_sigmoid.append(stats[-1, keys['error(valid)']])
    #     final_valid_acc_sigmoid.append(stats[-1, keys['acc(valid)']])
    # plot the accuracy for each layer
    ax1.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['error(valid)']])
    ax2.plot(
        np.arange(1, stats.shape[0]) * stats_interval,
        stats[1:, keys['acc(valid)']], 
        label=layer)
    
ax2.legend(loc='best');
ax1.set_ylabel('validation error')
ax2.set_ylabel('validation accuracy')
ax2.set_xlabel('epoch number')

from mlp.layers import BatchNormalizationLayer
experiment_layers_BN_sigmoid = {}

# It is said the batchnorm prevent the network fro getting stuck in the saturated nodes - try with sigmoid:

for i in range(1,10):
    # reinitialisation of func needed for every expt!
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init),
        BatchNormalizationLayer(input_dim=hidden_dim, rng=rng)
    ]
    output_layer = [
        SigmoidLayer(),
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        SigmoidLayer(),
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init),
        BatchNormalizationLayer(input_dim=hidden_dim, rng=rng),
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_layers_BN_sigmoid[i + 1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

experiment_layers_BN_relu = {}

for i in range(1,10):
    # reinitialisation of func needed for every expt!
    train_data.reset()
    test_data.reset()
    valid_data.reset()

    # Initialise the weights and biases:
    weights_init = GlorotUniformInit(rng=rng)
    biases_init = ConstantInit(0.)

    input_layer = [
        AffineLayer(input_dim, hidden_dim, weights_init, biases_init),
        BatchNormalizationLayer(input_dim=hidden_dim, rng=rng)
    ]
    output_layer = [
        ReluLayer(),
        AffineLayer(hidden_dim, output_dim, weights_init, biases_init)
    ]
    each_hidden_layer = [
        ReluLayer(),
        AffineLayer(hidden_dim, hidden_dim, weights_init, biases_init),
        BatchNormalizationLayer(input_dim=hidden_dim, rng=rng),
    ]

    # create the MLP:
    model = MultipleLayerModel(input_layer + each_hidden_layer * i +
                               output_layer)
    print(model, '{} layers'.format(i + 1))

    error = CrossEntropyLogSoftmaxError()
    learning_rule = GradientDescentLearningRule(learning_rate=learning_rate)

    experiment_layers_BN_relu[i + 1] = train_model_and_plot_stats(
        model,
        error,
        learning_rule,
        train_data,
        valid_data,
        test_data,
        num_epochs,
        stats_interval,
        notebook=False)

import pickle as pkl

# Save the stuff:
pkl.dump(experiment_units_elu, open('./experiment_units_elu.pkl', 'wb'), protocol=-1)

# Save the stuff:
pkl.dump(experiment_layers_elu, open('./experiment_layers_elu.pkl', 'wb'), protocol=-1)

# Save the stuff:
pkl.dump(experiment_layers_relu, open('./experiment_layers_relu.pkl', 'wb'), protocol=-1)

# Save the stuff:
pkl.dump(experiment_layers_selu, open('./experiment_layers_selu.pkl', 'wb'), protocol=-1)

# Save the stuff:
pkl.dump(experiment_layers_sigmoid, open('./experiment_layers_sigmoid.pkl', 'wb'), protocol=-1)
